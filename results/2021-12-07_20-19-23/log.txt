2021-12-07 20:19:23 - INFO - saving to ./results/2021-12-07_20-19-23
2021-12-07 20:19:23 - DEBUG - run arguments: Namespace(batch_size=96, dataset='cifar10', epochs=250, evaluate=None, gpus='0', input_size=None, lr=0.1, model='alexnet', model_config='', momentum=0.9, optimizer='SGD', print_freq=10, results_dir='./results', resume='', save='2021-12-07_20-19-23', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0.0001, workers=8)
2021-12-07 20:19:23 - INFO - creating model fake generator (student)
2021-12-07 20:19:23 - INFO - creating model real generator (student)
2021-12-07 20:19:24 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10'}
2021-12-07 20:19:24 - INFO - number of parameters: 11094174
2021-12-07 20:19:25 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.005}, 101: {'lr': 0.001}, 142: {'lr': 0.0005}, 184: {'lr': 0.0001}, 220: {'lr': 1e-05}}
2021-12-07 20:19:26 - INFO - TRAINING - Epoch: [0][0/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6779 (2.6779)	Prec@1 8.333 (8.333)	Prec@5 55.208 (55.208)
2021-12-07 20:19:28 - INFO - TRAINING - Epoch: [0][10/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7931 (2.7102)	Prec@1 6.250 (8.996)	Prec@5 46.875 (49.905)
2021-12-07 20:19:30 - INFO - TRAINING - Epoch: [0][20/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6942 (2.6895)	Prec@1 8.333 (10.020)	Prec@5 50.000 (50.744)
2021-12-07 20:19:32 - INFO - TRAINING - Epoch: [0][30/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6856 (2.6913)	Prec@1 9.375 (10.081)	Prec@5 50.000 (51.378)
2021-12-07 20:19:34 - INFO - TRAINING - Epoch: [0][40/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6441 (2.6917)	Prec@1 9.375 (10.264)	Prec@5 52.083 (51.143)
2021-12-07 20:19:36 - INFO - TRAINING - Epoch: [0][50/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6584 (2.6981)	Prec@1 12.500 (10.294)	Prec@5 52.083 (50.878)
2021-12-07 20:19:39 - INFO - TRAINING - Epoch: [0][60/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7874 (2.7030)	Prec@1 7.292 (10.195)	Prec@5 43.750 (50.683)
2021-12-07 20:19:41 - INFO - TRAINING - Epoch: [0][70/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.9049 (2.7027)	Prec@1 5.208 (10.123)	Prec@5 45.833 (50.704)
2021-12-07 20:19:43 - INFO - TRAINING - Epoch: [0][80/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6967 (2.7110)	Prec@1 12.500 (10.159)	Prec@5 48.958 (50.386)
2021-12-07 20:19:45 - INFO - TRAINING - Epoch: [0][90/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6827 (2.7112)	Prec@1 10.417 (10.199)	Prec@5 52.083 (50.366)
2021-12-07 20:19:47 - INFO - TRAINING - Epoch: [0][100/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.5890 (2.7090)	Prec@1 13.542 (10.262)	Prec@5 57.292 (50.454)
2021-12-07 20:19:49 - INFO - TRAINING - Epoch: [0][110/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6513 (2.7099)	Prec@1 13.542 (10.417)	Prec@5 45.833 (50.375)
2021-12-07 20:19:51 - INFO - TRAINING - Epoch: [0][120/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6807 (2.7078)	Prec@1 8.333 (10.520)	Prec@5 56.250 (50.620)
2021-12-07 20:19:53 - INFO - TRAINING - Epoch: [0][130/520]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7692 (2.7087)	Prec@1 10.417 (10.480)	Prec@5 46.875 (50.588)

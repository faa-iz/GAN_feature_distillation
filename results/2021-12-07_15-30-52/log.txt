2021-12-07 15:30:52 - INFO - saving to ./results/2021-12-07_15-30-52
2021-12-07 15:30:52 - DEBUG - run arguments: Namespace(batch_size=128, dataset='cifar10', epochs=250, evaluate=None, gpus='0', input_size=None, lr=0.1, model='alexnet', model_config='', momentum=0.9, optimizer='SGD', print_freq=10, results_dir='./results', resume='', save='2021-12-07_15-30-52', start_epoch=0, type='torch.cuda.FloatTensor', weight_decay=0.0001, workers=8)
2021-12-07 15:30:52 - INFO - creating model fake generator (student)
2021-12-07 15:30:52 - INFO - creating model real generator (student)
2021-12-07 15:30:53 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10'}
2021-12-07 15:30:53 - INFO - number of parameters: 11094174
2021-12-07 15:30:54 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.005}, 101: {'lr': 0.001}, 142: {'lr': 0.0005}, 184: {'lr': 0.0001}, 220: {'lr': 1e-05}}
2021-12-07 15:30:56 - INFO - TRAINING - Epoch: [0][0/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7710 (2.7710)	Prec@1 7.031 (7.031)	Prec@5 50.000 (50.000)
2021-12-07 15:30:59 - INFO - TRAINING - Epoch: [0][10/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.4853 (2.6342)	Prec@1 11.719 (9.446)	Prec@5 44.531 (49.858)
2021-12-07 15:31:01 - INFO - TRAINING - Epoch: [0][20/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.3320 (2.4954)	Prec@1 9.375 (9.673)	Prec@5 55.469 (49.330)
2021-12-07 15:31:04 - INFO - TRAINING - Epoch: [0][30/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7056 (2.5116)	Prec@1 10.156 (10.207)	Prec@5 50.781 (50.202)
2021-12-07 15:31:07 - INFO - TRAINING - Epoch: [0][40/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6791 (2.5768)	Prec@1 9.375 (10.080)	Prec@5 51.562 (50.133)
2021-12-07 15:31:09 - INFO - TRAINING - Epoch: [0][50/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.3433 (2.5614)	Prec@1 7.812 (10.218)	Prec@5 51.562 (49.954)
2021-12-07 15:31:12 - INFO - TRAINING - Epoch: [0][60/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.4655 (2.5299)	Prec@1 7.812 (10.348)	Prec@5 50.781 (49.936)
2021-12-07 15:31:15 - INFO - TRAINING - Epoch: [0][70/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.5884 (2.5434)	Prec@1 10.938 (10.387)	Prec@5 55.469 (50.044)
2021-12-07 15:31:17 - INFO - TRAINING - Epoch: [0][80/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.6686 (2.5720)	Prec@1 10.938 (10.291)	Prec@5 50.000 (49.855)
2021-12-07 15:31:20 - INFO - TRAINING - Epoch: [0][90/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.3211 (2.5572)	Prec@1 15.625 (10.242)	Prec@5 49.219 (50.043)
2021-12-07 15:31:23 - INFO - TRAINING - Epoch: [0][100/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.4458 (2.5407)	Prec@1 8.594 (10.164)	Prec@5 58.594 (50.178)
2021-12-07 15:31:27 - INFO - TRAINING - Epoch: [0][110/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.7194 (2.5511)	Prec@1 11.719 (10.086)	Prec@5 45.312 (50.077)
2021-12-07 15:31:30 - INFO - TRAINING - Epoch: [0][120/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.5200 (2.5632)	Prec@1 12.500 (10.234)	Prec@5 57.812 (50.252)
2021-12-07 15:31:33 - INFO - TRAINING - Epoch: [0][130/390]	Time 0.000 (0.000)	Data 0.000 (0.000)	Loss 2.4009 (2.5624)	Prec@1 10.156 (10.287)	Prec@5 53.125 (50.155)
